---
title: Virtue Ethics, Missing Information, and Self-Control
date: 2019-02-14
tags: [misc]
---

What is the point is this piece?
- Canonical self-control is overrated
- Creating an environment with the correct incentives is much better
- This works really well for saving money and losing weight
- Funnily enough it also works for ethics?



I was feeling bad recently because I haven't actively invested any money
into my retirement savings in a few months. Mostly, this is the case
because I have roughly 25% of my salary invested through various
automatic channels, but since I don't see them, I don't feel like I'm saving
enough. I should have set out to create this system myself, but instead
my employer incentivized me to do it through stock discounts and a savings
matching program.

## Canonical Self-Control is Overrated
When I say canonical self-control, I'm referring to the idea of actively
resisting temptations and overcoming your own weakness to achieve the desired
outcome. The classic image of a chisel-jawed man staring into the distance
and saying "No, I will overcome!"

To be honest, I kinda love this method because it makes me feel like a
badass for the simplest things, like deciding to order a cheaper coffee
or not have a second piece of free cake. So strong. This method is popular
mostly for this reason, it makes you feel empowered. It would be cool if it
actually worked that well.

### Very Manly Self-Control in Action
To see what actually happens, consider an optimizing agent in a system
that rewards it for resisting temptation on the fly and penalizes it for
giving in to temptation. The rational choice becomes to expose itself
to the largest number of temptations that it is confident in being able to
resist. Assuming that the agent has a good estimate of its own abilities,
it will overcome all or nearly all the temptations.

So what's the problem?
The first problem is that constant effort is needed. The second problem
is that we aren't directly measuring and rewarding achieving the
goal, just one pattern of behavior that might correlate with it (or not).
Basically, the incentives are not well aligned


### Better Incentives
Another approach is to feel good about transferring money to a savings
account. This is much better than the first method, but still not that good.
I've been using this method for a while because it is fun to actively transfer
funds every month and know that my savings are going up. It gave me a
little regular hit of dopamine and feelings of moral superiority for every
transfer I did.

Money being saved is the measured variable, but the concept of how much
to save is left open to interpretation. This control is also the farthest
downstream, since the money is taken from whatever I have left at the end
of a month, making it more vulnerable to the events of that month.
Even if I fix it at 25% of my salary, it leaves open opportunities for
messing it up by considering that month to be exceptional in some way.
The controller is still stuck inside the system that we're trying to control.

### Removing Real-Time Control 
I have read from many, many sources that automating savings was the best
system for saving for retirement or paying down debts (same thing).
With this approach I choose to save 25% of my salary, have it removed
every time I receive any form of income, and soon forget that I'm even doing
it. It is optimal because the amount that we target saving is exactly the
amount that actually gets saved, without exception.

### The Cost of Active Control
So even though I knew it was optimal, I still didn't use an automated
approach because I was putting a lot of value on feeling heroic by
investing in a more hands-on way. I actually think this is valid, but before
accepting it, I should have put a dollar amount to how much I'm valuing
my little hits of dopamine and see if I think it is worth that amount.

TODO: some calcs to put a price on the difference between lopping and
tithing, and also "avoiding spending."

Another way to spin this is that I've just named the price for changing
my own attitude to consider automated savings equally badass. Sold.

### Getting What You Pay For
Systems will (mostly) come into line with their environmental incentives, but
that also holds true when they've been designed badly.

One recent example is in the California wildfires, where the state made
the mistake of paying cleanup crews by weight for removal of debris.
Unsurprisingly, debris removal crews removed a lot of mass from every
site they visited. One man returned to find a large hole where his home had
been, since the cleanup crews had opted to make more money by removing
several meters of dirt beneath his burned out home.


Part 2 - Self-Control Systems

# Active Control, Why We Like It
Some self-help types talk about taking responsibility, practicing self-control,
discipline, etc. Being good at life is the result of overcoming these
obstacles and controlling yourself perfectly, actively.
This approach makes me feel like a hero every time I complete an
arbitrary self-control action, regardless of the outcomes. It doesn't
"pay for" the things we actually want.

Another dimension to active control is that it presumes efficacy. I don't
really think this is a safe assumption. We are incredibly complicated systems
and considering that the designer of the control system, the control system
itself, and the system under control are all the same system, things can
get really messy. We can fix a lot of this by moving the controller out
of the self, and into the environment.


# Passive Control, Why We Should Like It
As I've grown less arrogant with age, I've come around to the idea that
I can't fully control myself, and morever that it is a waste effort to try
and do so. Maybe I'd feel differently if signaling that I am the paragon
of self-discipline actually benefited me, rather than making me look like
a teenager had that recently encountered a handful of Nietzche quotes.

TODO: a picture would be good here... maybe "how I imagine myself" and a
"how everyone else sees me" type meme with a superman and a gangly kid
muttering about how he is right on the internet...

Passive control is the idea of setting up your incentives and feedback
loops in advance, rather than trying to control actively in the moment.
A related idea that I'll lump in is the idea of "usually winning,"
meaning that it isn't critical to always achieve the desired behavior,
just most of the time, which is also the idea of pareto optimality, or the
"80/20" rule, which states that all blog posts that discuss any type of
self-improvement must mention pareto optimality.

Moving control into the environment is a way to split the currently acting
controller out of the system under control, meaning that it will not
necessarily be influenced by whatever factors are influencing the system.

If the issue is spending too much money specifiically on coffees, then
changing ones route to avoid cafes, not carrying a coffee-shop rewards card,
and messing up your schedule to make it more difficult to get coffee are all
effective ways to create environmental pressures against buying coffee.

# Retirement Savings Control Systems
I mentioned before how I felt empowered when I approached savings
by "choosing not to spend money." The problem is that it isn't effective.
If I get to feel like a hero every single time that I choose to not buy a
latte, I'm not controlling for the amount of money saved, but rather the
binary outcome of every spending opportunity. This system affects control
by me feeling bad when I fail and good when I succeed.
If we follow the money, a system optimizing for this incentive will seek
out as many opportunities to spend money as possible, and then reject all
of them. There is no necessarily correlation between this behavior and
the result of having a high savings rate into your retirement account.

A half-step from here is the system I was recently using: investing chunks of
money into my retirement account and feeling good about it. A system
optimizing for this incentive will contribute chunks of money to the
retirement savings account very often. There is also a level of control
on the size of the contributions, but it is flimsily defined as feeling
"significant." This system is not bad, but it doesn't play out as well
in the long term as our next one.

A fully environmental approach is to set up, once, for money to be siphoned
off from every bit of your income automatically. This is really common advice,
but I liked to think that I was above it because I am just so
amazingly disciplined. The underappreciated piece of beauty about this
approach is what variable it controls -- a savings percentage.

If we control for investing significant chunks of money regularly, we fall
into a trap with our definition of significance. There is guarantee that
our notion of a significant chunk will rise exactly with our income. It is
more likely that it will rise with our perception of our available income,
and that the significance can also be modified by whatever events are
occurring that month. The tithing method is immune in the face of both
income growth and weird months.

TODO: need nicknames for these methods.

The first method, rewarding acts of not spending, has no necessary
correlation with the actual effect. The second method, investing chunks
that feel significant, is effective, but sub-optimal. The third method,
tithing your desired savings rate directly from your pay, is optimal, since
it directly controls for what you want.

TODO: this is crap and the flow makes no sense.

Part 3 - Ethics!
Holy shit, how did we get here?

## Utilitarianism is Optimal Caching
In computing, there is the concept of a cache, where you can go to look
up a value at lower cost than normal. These are space-limited and so
we have many strategies for deciding what goes in the cache and how long
it stays there. The optimal caching strategy, mathematically speaking,
is to cache all the things you will ever need to look up. Unfortunately,
since we are not omniscient, we don't actually know what will need to be
looked up in the future. So even though this strategy is optimal for caching,
it is also completely useless because it is not actionable.

Utilitarianism is an ethical framework that I'll flimsily define as
"looking at the possible outcomes and choosing the path with the best one."
Great! So utilitarianism is optimal caching, but for ethics: useful for the
omniscient. I used to think of myself as a utilitarian, but like other things,
I changed my mind as I became less arrogant. Now a'days I consider myself more 
alined with virtue ethics.

## Virtue Ethics and Imperfect Information
I actually don't know what to say about value ethics. Do 


OUTLINE
Part 1 - Control Systems
1. Context, saving money.
2. Controller and controllee.
3. Control at different abstraction levels
4. Getting what you pay for
5. Enforcement vs aligning incentives

Part 2- Self-Control Systems
1. Active control, the narratives, why we like it.
2. Passive control, why we should learn to like it's narrative instead.

Part 3 - Ethical Systems
1. Utilitarianism is optimal caching.
2. Virtue ethics and why we should like it more.

